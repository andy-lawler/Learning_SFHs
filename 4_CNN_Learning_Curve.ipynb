{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pcl\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=False)\n",
    "\n",
    "from methods.training import load_data\n",
    "\n",
    "from predict import predict\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(inst, size, features, predictors, smape_train, smape_test, n_splits=3):\n",
    "    \n",
    "    if size > len(features):\n",
    "        print('chosen size larger than number of features.')\n",
    "        return None\n",
    "#         raise ValueError('chosen size larger than number of features.')\n",
    "\n",
    "    test_frac = 1 - (size / len(features))\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_frac)\n",
    "\n",
    "    for j, (train, test) in enumerate(ss.split(features)):\n",
    "\n",
    "        tra = np.zeros(len(features), dtype='bool')\n",
    "        tra[train] = True\n",
    "\n",
    "        model, scores = inst.create_cnn_model(features, predictors, batch_size=10, train=tra, \n",
    "                                            plot=False, verbose=False)\n",
    "\n",
    "        smape_test[size][j] = scores['loss']\n",
    "        smape_train[size][j], mae, mse, acc = model.evaluate(features[train], predictors[train], verbose=0)\n",
    "\n",
    "\n",
    "    return smape_train, smape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6\n",
    "train_sizes =np.arange(200,10000,step=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = predict(fname='data/full_histories_illustris.h5')\n",
    "\n",
    "illustris_dust_noise, wl = si.load_spectra('Noisified Dust')\n",
    "features = si.prepare_features(illustris_dust_noise, key='Dust Noise SN50', CNN=True)\n",
    "\n",
    "predictors = si.load_arr('log_8','SFH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "500\n",
      "800\n",
      "1100\n",
      "1400\n",
      "1700\n",
      "2000\n",
      "2300\n",
      "2600\n",
      "2900\n",
      "3200\n",
      "3500\n",
      "3800\n",
      "4100\n",
      "4400\n",
      "4700\n",
      "5000\n",
      "5300\n",
      "5600\n",
      "5900\n",
      "train...\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00105: early stopping\n",
      "Test SMAPE: 0.13499420270141715\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00174: early stopping\n",
      "Test SMAPE: 0.13205882506428795\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00154: early stopping\n",
      "Test SMAPE: 0.13299458022725102\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.1356817159093071\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.13535815279729288\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00110: early stopping\n",
      "Test SMAPE: 0.13571490308377132\n",
      "6200\n",
      "train...\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00114: early stopping\n",
      "Test SMAPE: 0.12999711854614482\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.12447217650657152\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00109: early stopping\n",
      "Test SMAPE: 0.12821773559290128\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00153: early stopping\n",
      "Test SMAPE: 0.12703906467361173\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00164: early stopping\n",
      "Test SMAPE: 0.11857234740996883\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00162: early stopping\n",
      "Test SMAPE: 0.12238532065475075\n",
      "6500\n",
      "train...\n",
      "chosen size larger than number of features.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-884f52e7123b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         smape_train, smape_test = learning_curve(size, features, predictors, \n\u001b[0;32m---> 12\u001b[0;31m                                              smape_train, smape_test, n_splits=n_splits)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmape_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmape_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/learning_curve_illustris.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# smape_train, smape_test = pcl.load(open('data/learning_curve_illustris.p', 'rb'))\n",
    "\n",
    "## uncomment to rewrite!\n",
    "# smape_test = {size: [None] * n_splits for size in train_sizes}\n",
    "# smape_train = {size: [None] * n_splits for size in train_sizes}\n",
    "\n",
    "for size in train_sizes:\n",
    "    print(size)\n",
    "    if smape_test[size][0] is None:\n",
    "        print(\"train...\")\n",
    "        smape_train, smape_test = learning_curve(si, size, features, predictors, \n",
    "                                                 smape_train, smape_test, n_splits=n_splits)\n",
    "        \n",
    "#         pcl.dump([smape_train, smape_test], open('data/learning_curve_illustris.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape_train = {key: val for key, val in smape_train.items() if val[0] is not None}\n",
    "# smape_test = {key: val for key, val in smape_test.items() if val[0] is not None}\n",
    "\n",
    "# pcl.dump([smape_train, smape_test], open('data/learning_curve_illustris.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = predict(fname='data/full_histories_eagle.h5')\n",
    "\n",
    "eagle_dust_noise, wl = se.load_spectra('Noisified Dust')\n",
    "features = se.prepare_features(eagle_dust_noise, key='Dust Noise SN50', CNN=True)\n",
    "\n",
    "predictors = se.load_arr('log_8','SFH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_test = {size: [None] * n_splits for size in train_sizes}\n",
    "smape_train = {size: [None] * n_splits for size in train_sizes}\n",
    "\n",
    "# smape_train, smape_test = pcl.load(open('data/learning_curve_eagle_hmass.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00116: early stopping\n",
      "Test SMAPE: 0.22353914898430546\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00118: early stopping\n",
      "Test SMAPE: 0.2416300189112195\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00098: early stopping\n",
      "Test SMAPE: 0.2395141111221565\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00122: early stopping\n",
      "Test SMAPE: 0.23641775313851346\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "Epoch 00038: early stopping\n",
      "Test SMAPE: 0.30897952589292665\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00100: early stopping\n",
      "Test SMAPE: 0.2302411144686388\n",
      "500\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00054: early stopping\n",
      "Test SMAPE: 0.22184389504213337\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00103: early stopping\n",
      "Test SMAPE: 0.20798294028780998\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00069: early stopping\n",
      "Test SMAPE: 0.22310038046998443\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00089: early stopping\n",
      "Test SMAPE: 0.2053100824786235\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00075: early stopping\n",
      "Test SMAPE: 0.2105320182140621\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00105: early stopping\n",
      "Test SMAPE: 0.21373367765909607\n",
      "800\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00114: early stopping\n",
      "Test SMAPE: 0.20987062629507122\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00067: early stopping\n",
      "Test SMAPE: 0.2092799427994899\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00067: early stopping\n",
      "Test SMAPE: 0.20811146835286518\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.20796639735739167\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00151: early stopping\n",
      "Test SMAPE: 0.18649955631169557\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00124: early stopping\n",
      "Test SMAPE: 0.19793109063628145\n",
      "1100\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00132: early stopping\n",
      "Test SMAPE: 0.19792727591726106\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00137: early stopping\n",
      "Test SMAPE: 0.1868052002174961\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.18168165146659662\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00107: early stopping\n",
      "Test SMAPE: 0.1884300984914373\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00142: early stopping\n",
      "Test SMAPE: 0.19075241295687015\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.18038458161781523\n",
      "1400\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00117: early stopping\n",
      "Test SMAPE: 0.17925738518186984\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.1702195193942687\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00150: early stopping\n",
      "Test SMAPE: 0.1694725683919196\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00122: early stopping\n",
      "Test SMAPE: 0.1688730092381201\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00144: early stopping\n",
      "Test SMAPE: 0.17168915317368183\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00138: early stopping\n",
      "Test SMAPE: 0.1741097226875757\n",
      "1700\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00146: early stopping\n",
      "Test SMAPE: 0.18477221733970622\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00125: early stopping\n",
      "Test SMAPE: 0.16713354632325908\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.16566107315997952\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.19491591998603275\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.16856710312050913\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00100: early stopping\n",
      "Test SMAPE: 0.16638540264704627\n",
      "2000\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.1605267697491445\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00184: early stopping\n",
      "Test SMAPE: 0.16051324722359855\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00166: early stopping\n",
      "Test SMAPE: 0.15742133442968326\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00115: early stopping\n",
      "Test SMAPE: 0.1665166079397377\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00173: early stopping\n",
      "Test SMAPE: 0.16568273007339746\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00165: early stopping\n",
      "Test SMAPE: 0.1711177559614747\n",
      "2300\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.16316598121302273\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00104: early stopping\n",
      "Test SMAPE: 0.16627781711497294\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00199: early stopping\n",
      "Test SMAPE: 0.16991464390019517\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.15805666380553837\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00158: early stopping\n",
      "Test SMAPE: 0.15642134226880086\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00150: early stopping\n",
      "Test SMAPE: 0.1574380609504771\n",
      "2600\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.15788576091882167\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00195: early stopping\n",
      "Test SMAPE: 0.15895444698967623\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00108: early stopping\n",
      "Test SMAPE: 0.15547913618611983\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00124: early stopping\n",
      "Test SMAPE: 0.16299113983557437\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.15718556400439887\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00135: early stopping\n",
      "Test SMAPE: 0.15836188992230082\n",
      "2900\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00149: early stopping\n",
      "Test SMAPE: 0.15560257253077311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00074: early stopping\n",
      "Test SMAPE: 0.167179678965554\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00173: early stopping\n",
      "Test SMAPE: 0.15508023591705017\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00117: early stopping\n",
      "Test SMAPE: 0.15123992380147666\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.15654428053311198\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.15249281337785298\n",
      "3200\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00152: early stopping\n",
      "Test SMAPE: 0.1413929428233475\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00149: early stopping\n",
      "Test SMAPE: 0.15447592197871599\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00171: early stopping\n",
      "Test SMAPE: 0.14934342146896926\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00165: early stopping\n",
      "Test SMAPE: 0.1553474786828776\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00138: early stopping\n",
      "Test SMAPE: 0.15434219285112913\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00174: early stopping\n",
      "Test SMAPE: 0.14705190502229284\n",
      "3500\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n"
     ]
    }
   ],
   "source": [
    "for size in train_sizes:\n",
    "    print(size)\n",
    "    smape_train, smape_test = learning_curve(se, size, features, predictors, \n",
    "                                             smape_train, smape_test, n_splits=n_splits)\n",
    "    \n",
    "    pcl.dump([smape_train, smape_test], open('data/learning_curve_eagle.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_train = {key: val for key, val in smape_train.items() if val[0] is not None}\n",
    "smape_test = {key: val for key, val in smape_test.items() if val[0] is not None}\n",
    "\n",
    "pcl.dump([smape_train, smape_test], open('data/learning_curve_eagle.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{200: [0.18052240133285521,\n",
       "  0.19491448104381562,\n",
       "  0.1797304767370224,\n",
       "  0.1849804949760437,\n",
       "  0.29238749384880064,\n",
       "  0.16817854285240175],\n",
       " 500: [0.19910478985309601,\n",
       "  0.1707080852985382,\n",
       "  0.21202455341815948,\n",
       "  0.1635660257935524,\n",
       "  0.17915558922290803,\n",
       "  0.18001784420013428],\n",
       " 800: [0.17927396297454834,\n",
       "  0.18766002357006073,\n",
       "  0.1832883131504059,\n",
       "  0.18241241931915284,\n",
       "  0.15275222003459932,\n",
       "  0.17074319183826447],\n",
       " 1100: [0.1700612306730437,\n",
       "  0.16419454957540736,\n",
       "  0.15325964477465737,\n",
       "  0.16225386056388041,\n",
       "  0.16609192575184836,\n",
       "  0.14815220739811089],\n",
       " 1400: [0.15148658198969706,\n",
       "  0.14719836958817073,\n",
       "  0.1480232266868864,\n",
       "  0.14292913172926222,\n",
       "  0.13971249269587652,\n",
       "  0.14352206238678525],\n",
       " 1700: [0.16311843851033378,\n",
       "  0.14635973765569574,\n",
       "  0.14569958462434657,\n",
       "  0.17495118113125072,\n",
       "  0.1405959488363827,\n",
       "  0.1470418281064314],\n",
       " 2000: [0.1422258597612381,\n",
       "  0.1328219987154007,\n",
       "  0.1329713749885559,\n",
       "  0.14338910973072053,\n",
       "  0.13781388688087465,\n",
       "  0.14838491332530976],\n",
       " 2300: [0.13897259116963545,\n",
       "  0.1481774709130329,\n",
       "  0.15124340730679975,\n",
       "  0.1452705303629153,\n",
       "  0.1409110049220882,\n",
       "  0.13745237536251986],\n",
       " 2600: [0.13750215612925015,\n",
       "  0.1364153342980605,\n",
       "  0.13778179365854998,\n",
       "  0.138309175830621,\n",
       "  0.13611618119936722,\n",
       "  0.13501937398543726],\n",
       " 2900: [0.13254367742045173,\n",
       "  0.1547425939296854,\n",
       "  0.13305673473867877,\n",
       "  0.1384601978803503,\n",
       "  0.13301122020030845,\n",
       "  0.13711343175378338],\n",
       " 3200: [0.13023057593502602,\n",
       "  0.13234332404394902,\n",
       "  0.1301515982784715,\n",
       "  0.13783394354102985,\n",
       "  0.13593631186273628,\n",
       "  0.12779902983788738],\n",
       " 3500: [0.1365143997498921,\n",
       "  0.1308057722023555,\n",
       "  0.1303795160480908,\n",
       "  0.13278318658896854,\n",
       "  0.1323614991222109,\n",
       "  0.13658296753679003]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smape_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape_train_e, smape_test_e = pcl.load(open('../derivedSFH/data/learning_curve_eagle_hmass.p', 'rb'))\n",
    "smape_train_e, smape_test_e = pcl.load(open('data/learning_curve_eagle.p', 'rb'))\n",
    "# smape_train_i, smape_test_i = pcl.load(open('../derivedSFH/data/learning_curve_illustris_hmass.p', 'rb'))\n",
    "smape_train_i, smape_test_i = pcl.load(open('data/learning_curve_illustris.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "med = np.median([smape_test_e[idx] for idx in smape_test_e.keys()], axis=1) * 100\n",
    "std = np.std([smape_test_e[idx] for idx in smape_test_e.keys()], axis=1) * 100\n",
    "\n",
    "plt.fill_between(np.array(list(smape_test_e.keys())), \n",
    "                          med-std,med+std,label='EAGLE', color='C0', alpha=0.5)\n",
    "\n",
    "e_line = plt.plot(np.array(list(smape_train_e.keys())), med, color='C0', ls='dashed')\n",
    "\n",
    "\n",
    "med = np.median([smape_test_i[idx] for idx in smape_test_i.keys()], axis=1) * 100\n",
    "std = np.std([smape_test_i[idx] for idx in smape_test_i.keys()], axis=1) * 100\n",
    "\n",
    "plt.fill_between(np.array(list(smape_test_i.keys())), \n",
    "                          med-std,med+std,label='EAGLE', color='C1', alpha=0.5)\n",
    "\n",
    "\n",
    "i_line = plt.plot(np.array(list(smape_test_i.keys())), med, color='C1', ls='dashed')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('N', size=14)\n",
    "plt.ylabel('SMAPE', size=14)\n",
    "\n",
    "plt.ylim(12,32)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "train_line = Line2D([0],[0],color='black', linestyle='dashed')\n",
    "test_line = Line2D([0],[0],color='black', linestyle='solid')\n",
    "plt.legend([e_line[0], i_line[0]],#, train_line, test_line], \n",
    "           ['EAGLE', 'Illustris'],#'Train', 'Test'], \n",
    "           frameon=False)\n",
    "\n",
    "# fig.savefig('plots/learning_curves.png', dpi=250, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
