{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/cl19abx/Learning_SFHs/venv/lib64/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle as pcl\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "rc('text', usetex=False)\n",
    "\n",
    "from methods.training import load_data\n",
    "\n",
    "from predict import predict\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(inst, size, features, predictors, smape_train, smape_test, n_splits=3):\n",
    "    \n",
    "    if size > len(features):\n",
    "        print('chosen size larger than number of features.')\n",
    "        return None\n",
    "#         raise ValueError('chosen size larger than number of features.')\n",
    "\n",
    "    test_frac = 1 - (size / len(features))\n",
    "\n",
    "    ss = ShuffleSplit(n_splits=n_splits, test_size=test_frac)\n",
    "\n",
    "    for j, (train, test) in enumerate(ss.split(features)):\n",
    "\n",
    "        tra = np.zeros(len(features), dtype='bool')\n",
    "        tra[train] = True\n",
    "\n",
    "        model, scores = inst.create_cnn_model(features, predictors, batch_size=10, train=tra, \n",
    "                                            plot=False, verbose=False)\n",
    "\n",
    "        smape_test[size][j] = scores['loss']\n",
    "        smape_train[size][j], mae, mse, acc = model.evaluate(features[train], predictors[train], verbose=0)\n",
    "\n",
    "\n",
    "    return smape_train, smape_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6\n",
    "train_sizes =np.arange(200,10000,step=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Illustris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = predict(fname='data/full_histories_illustris.h5')\n",
    "\n",
    "illustris_dust_noise, wl = si.load_spectra('Noisified Dust')\n",
    "features = si.prepare_features(illustris_dust_noise, key='Dust Noise SN50', CNN=True)\n",
    "\n",
    "predictors = si.load_arr('log_8','SFH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "500\n",
      "800\n",
      "1100\n",
      "1400\n",
      "1700\n",
      "2000\n",
      "2300\n",
      "2600\n",
      "2900\n",
      "3200\n",
      "3500\n",
      "3800\n",
      "4100\n",
      "4400\n",
      "4700\n",
      "5000\n",
      "5300\n",
      "5600\n",
      "5900\n",
      "train...\n",
      "\n",
      "Epoch 00089: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00105: early stopping\n",
      "Test SMAPE: 0.13499420270141715\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00157: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00174: early stopping\n",
      "Test SMAPE: 0.13205882506428795\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00154: early stopping\n",
      "Test SMAPE: 0.13299458022725102\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.1356817159093071\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.13535815279729288\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00110: early stopping\n",
      "Test SMAPE: 0.13571490308377132\n",
      "6200\n",
      "train...\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00114: early stopping\n",
      "Test SMAPE: 0.12999711854614482\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.12447217650657152\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00109: early stopping\n",
      "Test SMAPE: 0.12821773559290128\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00153: early stopping\n",
      "Test SMAPE: 0.12703906467361173\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00160: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00164: early stopping\n",
      "Test SMAPE: 0.11857234740996883\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00143: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00162: early stopping\n",
      "Test SMAPE: 0.12238532065475075\n",
      "6500\n",
      "train...\n",
      "chosen size larger than number of features.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-884f52e7123b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         smape_train, smape_test = learning_curve(size, features, predictors, \n\u001b[0;32m---> 12\u001b[0;31m                                              smape_train, smape_test, n_splits=n_splits)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpcl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmape_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmape_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/learning_curve_illustris.p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# smape_train, smape_test = pcl.load(open('data/learning_curve_illustris.p', 'rb'))\n",
    "\n",
    "## uncomment to rewrite!\n",
    "# smape_test = {size: [None] * n_splits for size in train_sizes}\n",
    "# smape_train = {size: [None] * n_splits for size in train_sizes}\n",
    "\n",
    "for size in train_sizes:\n",
    "    print(size)\n",
    "    if smape_test[size][0] is None:\n",
    "        print(\"train...\")\n",
    "        smape_train, smape_test = learning_curve(si, size, features, predictors, \n",
    "                                                 smape_train, smape_test, n_splits=n_splits)\n",
    "        \n",
    "#         pcl.dump([smape_train, smape_test], open('data/learning_curve_illustris.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape_train = {key: val for key, val in smape_train.items() if val[0] is not None}\n",
    "# smape_test = {key: val for key, val in smape_test.items() if val[0] is not None}\n",
    "\n",
    "# pcl.dump([smape_train, smape_test], open('data/learning_curve_illustris.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EAGLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = predict(fname='data/full_histories_eagle.h5')\n",
    "\n",
    "eagle_dust_noise, wl = se.load_spectra('Noisified Dust')\n",
    "features = se.prepare_features(eagle_dust_noise, key='Dust Noise SN50', CNN=True)\n",
    "\n",
    "predictors = se.load_arr('log_8','SFH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_test = {size: [None] * n_splits for size in train_sizes}\n",
    "smape_train = {size: [None] * n_splits for size in train_sizes}\n",
    "\n",
    "# smape_train, smape_test = pcl.load(open('data/learning_curve_eagle_hmass.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00116: early stopping\n",
      "Test SMAPE: 0.22353914898430546\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00114: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00118: early stopping\n",
      "Test SMAPE: 0.2416300189112195\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00098: early stopping\n",
      "Test SMAPE: 0.2395141111221565\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00102: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00122: early stopping\n",
      "Test SMAPE: 0.23641775313851346\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "Epoch 00038: early stopping\n",
      "Test SMAPE: 0.30897952589292665\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00100: early stopping\n",
      "Test SMAPE: 0.2302411144686388\n",
      "500\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00054: early stopping\n",
      "Test SMAPE: 0.22184389504213337\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00103: early stopping\n",
      "Test SMAPE: 0.20798294028780998\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00069: early stopping\n",
      "Test SMAPE: 0.22310038046998443\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "Epoch 00089: early stopping\n",
      "Test SMAPE: 0.2053100824786235\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00075: early stopping\n",
      "Test SMAPE: 0.2105320182140621\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00105: early stopping\n",
      "Test SMAPE: 0.21373367765909607\n",
      "800\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00114: early stopping\n",
      "Test SMAPE: 0.20987062629507122\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00067: early stopping\n",
      "Test SMAPE: 0.2092799427994899\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00067: early stopping\n",
      "Test SMAPE: 0.20811146835286518\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.20796639735739167\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00147: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00151: early stopping\n",
      "Test SMAPE: 0.18649955631169557\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00124: early stopping\n",
      "Test SMAPE: 0.19793109063628145\n",
      "1100\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00132: early stopping\n",
      "Test SMAPE: 0.19792727591726106\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00137: early stopping\n",
      "Test SMAPE: 0.1868052002174961\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.18168165146659662\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00107: early stopping\n",
      "Test SMAPE: 0.1884300984914373\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00138: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00142: early stopping\n",
      "Test SMAPE: 0.19075241295687015\n",
      "\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.18038458161781523\n",
      "1400\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00117: early stopping\n",
      "Test SMAPE: 0.17925738518186984\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.1702195193942687\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00124: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00150: early stopping\n",
      "Test SMAPE: 0.1694725683919196\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00095: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00122: early stopping\n",
      "Test SMAPE: 0.1688730092381201\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00140: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00144: early stopping\n",
      "Test SMAPE: 0.17168915317368183\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00138: early stopping\n",
      "Test SMAPE: 0.1741097226875757\n",
      "1700\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00146: early stopping\n",
      "Test SMAPE: 0.18477221733970622\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00125: early stopping\n",
      "Test SMAPE: 0.16713354632325908\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00118: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.16566107315997952\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00094: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.19491591998603275\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00132: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00136: early stopping\n",
      "Test SMAPE: 0.16856710312050913\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00100: early stopping\n",
      "Test SMAPE: 0.16638540264704627\n",
      "2000\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.1605267697491445\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00180: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00184: early stopping\n",
      "Test SMAPE: 0.16051324722359855\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00097: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00162: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00166: early stopping\n",
      "Test SMAPE: 0.15742133442968326\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00080: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00115: early stopping\n",
      "Test SMAPE: 0.1665166079397377\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00133: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00142: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00153: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00173: early stopping\n",
      "Test SMAPE: 0.16568273007339746\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00128: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00149: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00165: early stopping\n",
      "Test SMAPE: 0.1711177559614747\n",
      "2300\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00126: early stopping\n",
      "Test SMAPE: 0.16316598121302273\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00104: early stopping\n",
      "Test SMAPE: 0.16627781711497294\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00177: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00199: early stopping\n",
      "Test SMAPE: 0.16991464390019517\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.15805666380553837\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00098: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00154: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00158: early stopping\n",
      "Test SMAPE: 0.15642134226880086\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00088: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00150: early stopping\n",
      "Test SMAPE: 0.1574380609504771\n",
      "2600\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00100: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00113: early stopping\n",
      "Test SMAPE: 0.15788576091882167\n",
      "\n",
      "Epoch 00085: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00150: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00182: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00195: early stopping\n",
      "Test SMAPE: 0.15895444698967623\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00108: early stopping\n",
      "Test SMAPE: 0.15547913618611983\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00124: early stopping\n",
      "Test SMAPE: 0.16299113983557437\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00107: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.15718556400439887\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00135: early stopping\n",
      "Test SMAPE: 0.15836188992230082\n",
      "2900\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00149: early stopping\n",
      "Test SMAPE: 0.15560257253077311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "Epoch 00074: early stopping\n",
      "Test SMAPE: 0.167179678965554\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00105: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00144: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00169: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00173: early stopping\n",
      "Test SMAPE: 0.15508023591705017\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00113: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "Epoch 00117: early stopping\n",
      "Test SMAPE: 0.15123992380147666\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00090: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00143: early stopping\n",
      "Test SMAPE: 0.15654428053311198\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00104: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00130: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00134: early stopping\n",
      "Test SMAPE: 0.15249281337785298\n",
      "3200\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00117: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "Epoch 00152: early stopping\n",
      "Test SMAPE: 0.1413929428233475\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "Epoch 00149: early stopping\n",
      "Test SMAPE: 0.15447592197871599\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00112: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00129: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00167: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00171: early stopping\n",
      "Test SMAPE: 0.14934342146896926\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00165: early stopping\n",
      "Test SMAPE: 0.1553474786828776\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00084: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00115: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00125: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00134: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00138: early stopping\n",
      "Test SMAPE: 0.15434219285112913\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00093: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n",
      "\n",
      "Epoch 00148: ReduceLROnPlateau reducing learning rate to 2.1874999220017344e-05.\n",
      "\n",
      "Epoch 00158: ReduceLROnPlateau reducing learning rate to 1.0937499610008672e-05.\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 5.468749805004336e-06.\n",
      "Epoch 00174: early stopping\n",
      "Test SMAPE: 0.14705190502229284\n",
      "3500\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003499999875202775.\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00017499999376013875.\n",
      "\n",
      "Epoch 00064: ReduceLROnPlateau reducing learning rate to 8.749999688006938e-05.\n",
      "\n",
      "Epoch 00103: ReduceLROnPlateau reducing learning rate to 4.374999844003469e-05.\n"
     ]
    }
   ],
   "source": [
    "for size in train_sizes:\n",
    "    print(size)\n",
    "    smape_train, smape_test = learning_curve(se, size, features, predictors, \n",
    "                                             smape_train, smape_test, n_splits=n_splits)\n",
    "    \n",
    "    pcl.dump([smape_train, smape_test], open('data/learning_curve_eagle.p', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smape_train = {key: val for key, val in smape_train.items() if val[0] is not None}\n",
    "smape_test = {key: val for key, val in smape_test.items() if val[0] is not None}\n",
    "\n",
    "pcl.dump([smape_train, smape_test], open('data/learning_curve_eagle.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smape_train_e, smape_test_e = pcl.load(open('../derivedSFH/data/learning_curve_eagle_hmass.p', 'rb'))\n",
    "smape_train_e, smape_test_e = pcl.load(open('data/learning_curve_eagle.p', 'rb'))\n",
    "# smape_train_i, smape_test_i = pcl.load(open('../derivedSFH/data/learning_curve_illustris_hmass.p', 'rb'))\n",
    "smape_train_i, smape_test_i = pcl.load(open('data/learning_curve_illustris.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "med = np.median([smape_test_e[idx] for idx in smape_test_e.keys()], axis=1) * 100\n",
    "std = np.std([smape_test_e[idx] for idx in smape_test_e.keys()], axis=1) * 100\n",
    "\n",
    "plt.fill_between(np.array(list(smape_test_e.keys())), \n",
    "                          med-std,med+std, color='C0', alpha=0.5)\n",
    "\n",
    "e_line = plt.plot(np.array(list(smape_train_e.keys())), med, color='C0', ls='solid')\n",
    "\n",
    "\n",
    "med = np.median([smape_train_e[idx] for idx in smape_test_e.keys()], axis=1) * 100\n",
    "plt.plot(np.array(list(smape_train_e.keys())), med, color='C0', ls='dashed')\n",
    "\n",
    "\n",
    "med = np.median([smape_test_i[idx] for idx in smape_test_i.keys()], axis=1) * 100\n",
    "std = np.std([smape_test_i[idx] for idx in smape_test_i.keys()], axis=1) * 100\n",
    "\n",
    "plt.fill_between(np.array(list(smape_test_i.keys())), \n",
    "                          med-std,med+std, color='C1', alpha=0.5)\n",
    "\n",
    "i_line = plt.plot(np.array(list(smape_test_i.keys())), med, color='C1', ls='solid')\n",
    "\n",
    "med = np.median([smape_train_i[idx] for idx in smape_test_i.keys()], axis=1) * 100\n",
    "plt.plot(np.array(list(smape_test_i.keys())), med, color='C1', ls='dashed')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel('N (train)', size=14)\n",
    "plt.ylabel('SMAPE', size=14)\n",
    "\n",
    "plt.ylim(11,32)\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "train_line = Line2D([0],[0],color='black', linestyle='dashed')\n",
    "test_line = Line2D([0],[0],color='black', linestyle='solid')\n",
    "plt.legend([e_line[0], i_line[0], train_line, test_line], \n",
    "           ['EAGLE', 'Illustris','Train', 'Test'], \n",
    "           frameon=False)\n",
    "\n",
    "# fig.savefig('plots/learning_curves.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
